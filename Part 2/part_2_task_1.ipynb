{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "Final_file_path = \"cleaned_file.csv\"\n",
    "data = pd.read_csv(Final_file_path, low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"['polit']\" \"['fake']\" \"['reliabl']\" \"['bia']\" '[]' \"['clickbait']\"]\n",
      "[\"['polit']\" \"['fake']\" \"['reliabl']\" \"['bia']\" \"['clickbait']\"]\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "# Print alle unikke værdier i 'type' kolonnen\n",
    "print(data['type'].unique())\n",
    "\n",
    "# Fjern rækker hvor 'type' kolonnen har bestemte værdier\n",
    "data = data[~data['type'].isin([\"['satir']\", \"['conspiraci']\", \"['junksci']\", \"['unreli']\", \"['rumor']\", \"['unknown']\", \"['nan']\", \"['hate']\", \"['num', 'date', 'num', 'num', 'num']\", \"[]\"])]\n",
    "data = data.dropna(subset=[\"type\"])\n",
    "\n",
    "# Print alle unikke værdier i 'type' kolonnen efter fjernelse\n",
    "print(data['type'].unique())\n",
    "\n",
    "# Definér mapping\n",
    "label_mapping = {\n",
    "    \"political\": \"True\",\n",
    "    \"clickbait\": \"True\",\n",
    "    \"reliable\": \"True\",\n",
    "    \"fake\": \"Fake\",\n",
    "    \"bias\": \"Fake\"\n",
    "}\n",
    "\n",
    "# Opret label-kolonnen først\n",
    "data[\"label\"] = data[\"type\"].map(label_mapping)\n",
    "\n",
    "# Konverter 'True' til 1 og 'Fake' til 0\n",
    "data[\"label\"] = data[\"label\"].map({\"True\": 1, \"Fake\": 0})\n",
    "\n",
    "\n",
    "# Definér y (målvariabel)\n",
    "global y\n",
    "y = data[\"label\"].dropna().astype(int)\n",
    "\n",
    "# Tjek om det virker\n",
    "print(y.unique())  # Skal vise [1 0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\emilv\\AppData\\Local\\Temp\\ipykernel_12108\\1780782999.py:10: DtypeWarning: Columns (0) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  data = pd.read_csv(\"cleaned_file.csv\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-score: 0.7543\n",
      "Hyperparameters for Logistic Regression:\n",
      "Max Iterations: 500\n",
      "Solver: saga\n",
      "Random State: 42\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import f1_score\n",
    "import numpy as np\n",
    "\n",
    "# Load CSV\n",
    "data = pd.read_csv(\"cleaned_file.csv\")\n",
    "\n",
    "#Fjerner class with less than 1 sample\n",
    "min_samples = 2\n",
    "y_counts = pd.Series(y).value_counts()\n",
    "valid_classes = y_counts[y_counts >= min_samples].index\n",
    "\n",
    "#Vectorize text data\n",
    "vectorizer = TfidfVectorizer(max_features=10000, binary=True)\n",
    "X = vectorizer.fit_transform(data[\"content\"])\n",
    "\n",
    "# Filter dataset\n",
    "X_filtered = X[np.isin(y, valid_classes)]\n",
    "y_filtered = y[np.isin(y, valid_classes)]\n",
    "\n",
    "#Fjerner class with less than 1 sample\n",
    "min_samples = 2\n",
    "y_counts = pd.Series(y).value_counts()\n",
    "valid_classes = y_counts[y_counts >= min_samples].index\n",
    "\n",
    "# Ensure text data is string type\n",
    "data[\"content\"] = data[\"content\"].fillna(\"\").astype(str)\n",
    "data[\"type\"] = data[\"type\"].fillna(\"\").astype(str)\n",
    "\n",
    "\n",
    "\n",
    "# Encoding the labels\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(data[\"type\"])\n",
    "\n",
    "# Splitting dataset into train, validation, and test sets\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "# Implementing logistic regression\n",
    "clf = LogisticRegression(max_iter=500, random_state=42, solver=\"saga\", n_jobs=-1)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Evaluating the model\n",
    "y_pred = clf.predict(X_test)\n",
    "f1 = f1_score(y_test, y_pred, average=\"weighted\")  # Use 'weighted' for multi-class classification\n",
    "\n",
    "# Display results\n",
    "print(f\"F1-score: {f1:.4f}\")\n",
    "print(\"Hyperparameters for Logistic Regression:\")\n",
    "print(f\"Max Iterations: {clf.max_iter}\")\n",
    "print(f\"Solver: {clf.solver}\")\n",
    "print(f\"Random State: {clf.random_state}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_environment",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
