{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1: Data processing \n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 1: \n",
    "\n",
    "-   Beneath is code for:\n",
    "\n",
    "    -   structuring, processing and cleaning it \n",
    "\n",
    "    -   Tokenizeing the text\n",
    "\n",
    "    -   Removing stopwords and compute the size of vocabulary size after removing stopwords\n",
    "\n",
    "    -   Removing word variations with stemming, computing the size of the vocabulary and computing the reduction rate of the vocabulary size. \n",
    "\n",
    "(Tænker måske en code cell per punkt så det er nemt at se hvad der er hvad?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# structuring, processing and cleaning it "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenizeing the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing stopwords and compute the size of vocabulary size after removing stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing word variations with stemming, computeing the size of the vocabulary \n",
    "# and computing the reduction rate of the vocabulary size. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 2: \n",
    "\n",
    "Beneath is exploration of the 995K FakeNewsCorpus subset. \n",
    "\n",
    "1.  We are counting the number of URLs in the content\n",
    "\n",
    "2.  We arecounting the number of dates in the content\n",
    "\n",
    "3.  We arecounting the number of numeric values in the content\n",
    "\n",
    "4.  We are determining the 100 more frequent words that appear in the content\n",
    "\n",
    "5.  We plot the frequency of the 10000 most frequent words (any interesting patterns?)\n",
    "\n",
    "6.  We run the analysis in point 4 and 5 both before and after removing stopwords and applying stemming: do you see any difference?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CODE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.  Description of how we represented the FakeNewsCorpus dataset.\n",
    "\n",
    "2.  Did we discover any problems with the dataset?\n",
    "\n",
    "3.  Key properties of the dataset (Through statistics or visualization)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 3: Advanced Model \n",
    "\n",
    "Here we apply the data preporccessing pipeline the the 995.000 rows sampled from the FakeNewsCorpus. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Her kan der måske være en samlet celle med de tidligere cells "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 4: \n",
    "\n",
    "Here we split the resulting dataset into training, validation, and test splits. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CODE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2: Simple Logistic Regression Model\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 0:\n",
    "\n",
    "Here we implement baseline models for our Fake News Predictor. These are used to benchmark our more advanced models. We will use these to train a binary classifier to predict whether a news article is fake or real."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CODE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 1:\n",
    "\n",
    "Here we implement an train a simple logistic regression classifier usen a fixed vocabulary of 10.000 most frequent words, extracted from the content field, as input features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CODE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 2: \n",
    "\n",
    "Consideration whether or not it make sense to include meta-data features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 3: \n",
    "\n",
    "Here we apply the preprocessing pipeline to the extra reliable data we scraped during Graded Exercise 2, and add this to the training data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 3: Advanced Model\n",
    "---\n",
    "\n",
    "Creating the best Fake News predictor that we can"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 4: Evaluation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 1: \n",
    "\n",
    "Evaluating the performance of our simple and advanced models "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 2: \n",
    "\n",
    "Here we try the same exercise on the LIAR dataset, where we know the labels, and can thus immediatly calculate the performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CODE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 3: \n",
    "\n",
    "Comparing the results of this experiment to the results optained in task 1. Reporting our LIAR results as part of our report. Also test the perfromance of both our simple and Advanced model on LIAR dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CODE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 5: Conclusion\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Discussion of results we optained."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
