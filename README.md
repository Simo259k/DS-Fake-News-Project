# DS-Fake-News-Project
First year bachelor project in data science 


# Guidelines for processing of code
First, create a fresh virtual environment or make sure your existing environment does not contain conflicting packages. Next, run `pip install -r requirements.txt` to install all necessary libraries. The `requirements.txt` file includes the packages scikit-learn, nltk, and seaborn, which will automatically pull in their dependencies if they are not already present. This ensures you have a clean, consistent setup to run the code without conflicts.

Then, ensure that your directory is empty to avoid any filename conflicts.

## PART 1
- First, download the sample version of the FakeNewsCorpus and save it as `news_sample.csv`. Then, download the complete dataset and save it as `995,000_rows.csv`.
- After that, download the Jupyter Notebook `PART1.ipynb` from the `DS-Fake-News-Project/Part 1/` folder on GitHub and run it sequentially as arranged.

## PART 2
To execute the cells in "Part 2/Task_0_1_2_3" and "Part 2/More_exploration.ipynb", you first need to insure, that you have executed the cells in Part 1. This means that you should have a file called "cleaned_file.csv" in your working directory. Also, "output_big.txt" should also be in your working directory. However, this file shold already be present. 

{fig:type=bias}
{fig:type=clickbait}
{fig:type=conspiracy}
{fig:type=fake}
{fig:type=hate}
{fig:type=junksci}
{fig:type=political}
{fig:type=reliable}
{fig:type=rumor}
{fig:type=satire}
{fig:type=unknown}
{fig:type=unreliable}