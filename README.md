# DS-Fake-News-Project
First year bachelor project in data science 


# Guidelines for processing of code
First, create a fresh virtual environment or make sure your existing environment does not contain conflicting packages. Next, run `pip install -r requirements.txt` to install all necessary libraries. The `requirements.txt` file includes the packages scikit-learn, nltk, and seaborn, which will automatically pull in their dependencies if they are not already present. This ensures you have a clean, consistent setup to run the code without conflicts.

Then, ensure that your directory is empty to avoid any filename conflicts.

## PART 1
- First, download the sample version of the FakeNewsCorpus and save it as `news_sample.csv`. Then, download the complete dataset and save it as `995,000_rows.csv`.
- After that, download the Jupyter Notebook `PART1.ipynb` from the `DS-Fake-News-Project/Part 1/` folder on GitHub and run it sequentially as arranged.

## PART 2
To execute the cells in `Part 2/Task_0_1_2_3` and `Part 2/More_exploration.ipynb`, you first need to insure, that you have executed the cells in Part 1. This means that you should have a file called `cleaned_file.csv` in your working directory. Also, `output_big.txt` should also be in your working directory. However, this file shold already be present. 

## PART 3
To execute `AdvancedPart3_final.ipynb` you need to execute the files in Part 1 to provide you with `cleaned_file.csv`. Be sure, that this file is in the same directory as you're locating `AdvancedPart3_final.ipynb`. Execute the script in chronological order by clicking each codeblock or `run all`.

## PART 4
